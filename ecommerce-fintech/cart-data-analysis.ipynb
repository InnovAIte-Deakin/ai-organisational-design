{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dde4da82",
   "metadata": {},
   "source": [
    "# MCP Cart Analysis & Cart Data Server Integration\n",
    "\n",
    "This notebook demonstrates the integration between a Cart Data Server (running on port 3001) and a Model Context Protocol (MCP) server with a cart analysis tool. We'll:\n",
    "\n",
    "1. Set up a simple data server to provide customer cart data\n",
    "2. Analyze the cart data using various techniques\n",
    "3. Visualize the results\n",
    "\n",
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d18e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "from flask import Flask, jsonify, request\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018abf3",
   "metadata": {},
   "source": [
    "## 1. Setting Up Data Server on Port 3001\n",
    "\n",
    "First, we'll create a simple Flask server that runs on port 3001 and serves our customer cart data. We'll run this server in a separate thread so that we can continue to use the notebook while the server is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Flask application\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define the customer data\n",
    "customers = [\n",
    "  {\n",
    "    \"id\": \"cust01\",\n",
    "    \"name\": \"Alice\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod1\", \"name\": \"Laptop\", \"price\": 1200, \"quantity\": 1, \"category\": \"electronics\"},\n",
    "      {\"id\": \"prod2\", \"name\": \"Mouse\", \"price\": 25, \"quantity\": 2, \"category\": \"electronics\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust02\",\n",
    "    \"name\": \"Bob\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod3\", \"name\": \"T-Shirt\", \"price\": 15, \"quantity\": 3, \"category\": \"fashion\"},\n",
    "      {\"id\": \"prod4\", \"name\": \"Jeans\", \"price\": 45, \"quantity\": 1, \"category\": \"fashion\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust03\",\n",
    "    \"name\": \"Charlie\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod5\", \"name\": \"Coffee Maker\", \"price\": 85, \"quantity\": 1, \"category\": \"home\"},\n",
    "      {\"id\": \"prod6\", \"name\": \"Coffee Beans\", \"price\": 12, \"quantity\": 5, \"category\": \"grocery\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust04\",\n",
    "    \"name\": \"Diana\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod7\", \"name\": \"Headphones\", \"price\": 150, \"quantity\": 1, \"category\": \"electronics\"},\n",
    "      {\"id\": \"prod8\", \"name\": \"Power Bank\", \"price\": 40, \"quantity\": 1, \"category\": \"electronics\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust05\",\n",
    "    \"name\": \"Ethan\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod9\", \"name\": \"Sneakers\", \"price\": 70, \"quantity\": 2, \"category\": \"fashion\"},\n",
    "      {\"id\": \"prod10\", \"name\": \"Socks\", \"price\": 5, \"quantity\": 6, \"category\": \"fashion\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust06\",\n",
    "    \"name\": \"Fiona\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod11\", \"name\": \"Microwave\", \"price\": 200, \"quantity\": 1, \"category\": \"home\"},\n",
    "      {\"id\": \"prod12\", \"name\": \"Dinner Plates\", \"price\": 30, \"quantity\": 1, \"category\": \"home\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust07\",\n",
    "    \"name\": \"George\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod13\", \"name\": \"Smartphone\", \"price\": 900, \"quantity\": 1, \"category\": \"electronics\"},\n",
    "      {\"id\": \"prod14\", \"name\": \"Phone Case\", \"price\": 20, \"quantity\": 2, \"category\": \"electronics\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust08\",\n",
    "    \"name\": \"Hannah\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod15\", \"name\": \"Notebook\", \"price\": 3, \"quantity\": 10, \"category\": \"stationery\"},\n",
    "      {\"id\": \"prod16\", \"name\": \"Pen\", \"price\": 1.5, \"quantity\": 20, \"category\": \"stationery\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust09\",\n",
    "    \"name\": \"Ian\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod17\", \"name\": \"Backpack\", \"price\": 60, \"quantity\": 1, \"category\": \"fashion\"},\n",
    "      {\"id\": \"prod18\", \"name\": \"Water Bottle\", \"price\": 12, \"quantity\": 2, \"category\": \"accessories\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust10\",\n",
    "    \"name\": \"Julia\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod19\", \"name\": \"Blender\", \"price\": 100, \"quantity\": 1, \"category\": \"home\"},\n",
    "      {\"id\": \"prod20\", \"name\": \"Smoothie Cup\", \"price\": 8, \"quantity\": 3, \"category\": \"home\"}\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Add more customers\n",
    "more_customers = [\n",
    "  {\n",
    "    \"id\": \"cust11\",\n",
    "    \"name\": \"Kevin\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod21\", \"name\": \"Gaming Console\", \"price\": 450, \"quantity\": 1, \"category\": \"electronics\"},\n",
    "      {\"id\": \"prod22\", \"name\": \"Extra Controller\", \"price\": 60, \"quantity\": 1, \"category\": \"electronics\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust12\",\n",
    "    \"name\": \"Laura\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod23\", \"name\": \"Dress\", \"price\": 80, \"quantity\": 1, \"category\": \"fashion\"},\n",
    "      {\"id\": \"prod24\", \"name\": \"Scarf\", \"price\": 25, \"quantity\": 1, \"category\": \"fashion\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust13\",\n",
    "    \"name\": \"Mark\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod25\", \"name\": \"Drill Machine\", \"price\": 120, \"quantity\": 1, \"category\": \"tools\"},\n",
    "      {\"id\": \"prod26\", \"name\": \"Safety Glasses\", \"price\": 15, \"quantity\": 1, \"category\": \"tools\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust14\",\n",
    "    \"name\": \"Nina\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod27\", \"name\": \"Skincare Cream\", \"price\": 35, \"quantity\": 2, \"category\": \"beauty\"},\n",
    "      {\"id\": \"prod28\", \"name\": \"Lipstick\", \"price\": 20, \"quantity\": 1, \"category\": \"beauty\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust15\",\n",
    "    \"name\": \"Oscar\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod29\", \"name\": \"Office Chair\", \"price\": 180, \"quantity\": 1, \"category\": \"furniture\"},\n",
    "      {\"id\": \"prod30\", \"name\": \"Desk Lamp\", \"price\": 40, \"quantity\": 1, \"category\": \"furniture\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust16\",\n",
    "    \"name\": \"Paula\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod31\", \"name\": \"Cookware Set\", \"price\": 150, \"quantity\": 1, \"category\": \"home\"},\n",
    "      {\"id\": \"prod32\", \"name\": \"Cutting Board\", \"price\": 20, \"quantity\": 1, \"category\": \"home\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust17\",\n",
    "    \"name\": \"Quentin\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod33\", \"name\": \"Running Shoes\", \"price\": 90, \"quantity\": 1, \"category\": \"fashion\"},\n",
    "      {\"id\": \"prod34\", \"name\": \"Sports Watch\", \"price\": 130, \"quantity\": 1, \"category\": \"fashion\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust18\",\n",
    "    \"name\": \"Rachel\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod35\", \"name\": \"Air Fryer\", \"price\": 160, \"quantity\": 1, \"category\": \"home\"},\n",
    "      {\"id\": \"prod36\", \"name\": \"Cooking Oil Spray\", \"price\": 10, \"quantity\": 2, \"category\": \"grocery\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust19\",\n",
    "    \"name\": \"Sam\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod37\", \"name\": \"Yoga Mat\", \"price\": 45, \"quantity\": 1, \"category\": \"fitness\"},\n",
    "      {\"id\": \"prod38\", \"name\": \"Dumbbells\", \"price\": 70, \"quantity\": 2, \"category\": \"fitness\"}\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"cust20\",\n",
    "    \"name\": \"Tina\",\n",
    "    \"cart\": [\n",
    "      {\"id\": \"prod39\", \"name\": \"Baby Stroller\", \"price\": 250, \"quantity\": 1, \"category\": \"baby\"},\n",
    "      {\"id\": \"prod40\", \"name\": \"Baby Bottle\", \"price\": 15, \"quantity\": 4, \"category\": \"baby\"}\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "# Combine all customers\n",
    "customers.extend(more_customers)\n",
    "\n",
    "# Define API routes\n",
    "@app.route('/api/customers', methods=['GET'])\n",
    "def get_customers():\n",
    "    return jsonify(customers)\n",
    "\n",
    "@app.route('/api/customers/<customer_id>', methods=['GET'])\n",
    "def get_customer(customer_id):\n",
    "    customer = next((c for c in customers if c['id'] == customer_id), None)\n",
    "    if customer:\n",
    "        return jsonify(customer)\n",
    "    return jsonify({\"error\": \"Customer not found\"}), 404\n",
    "\n",
    "@app.route('/api/customers/<customer_id>/cart', methods=['GET'])\n",
    "def get_customer_cart(customer_id):\n",
    "    customer = next((c for c in customers if c['id'] == customer_id), None)\n",
    "    if customer:\n",
    "        return jsonify(customer['cart'])\n",
    "    return jsonify({\"error\": \"Customer not found\"}), 404\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\"status\": \"ok\"})\n",
    "\n",
    "# Function to run the Flask app in a separate thread\n",
    "def run_flask_app():\n",
    "    app.run(host='localhost', port=3001, debug=False, use_reloader=False)\n",
    "\n",
    "# Create and start the server thread\n",
    "server_thread = threading.Thread(target=run_flask_app)\n",
    "server_thread.daemon = True  # Thread will exit when the main program exits\n",
    "server_thread.start()\n",
    "\n",
    "# Wait a moment for the server to start\n",
    "time.sleep(2)\n",
    "print(\"Cart Data Server is running on http://localhost:3001\")\n",
    "print(\"API endpoints available:\")\n",
    "print(\"- http://localhost:3001/api/customers\")\n",
    "print(\"- http://localhost:3001/api/customers/<customer_id>\")\n",
    "print(\"- http://localhost:3001/api/customers/<customer_id>/cart\")\n",
    "print(\"- http://localhost:3001/health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d8d965",
   "metadata": {},
   "source": [
    "## 2. Testing the Cart Data Server\n",
    "\n",
    "Let's verify that our server is working by making a few requests to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e7c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the health endpoint\n",
    "health_response = requests.get('http://localhost:3001/health')\n",
    "print(\"Health check response:\", health_response.json())\n",
    "\n",
    "# Test getting all customers\n",
    "customers_response = requests.get('http://localhost:3001/api/customers')\n",
    "print(f\"Retrieved {len(customers_response.json())} customers\")\n",
    "\n",
    "# Test getting a specific customer\n",
    "customer_response = requests.get('http://localhost:3001/api/customers/cust01')\n",
    "print(\"\\nCustomer details:\")\n",
    "print(json.dumps(customer_response.json(), indent=2))\n",
    "\n",
    "# Test getting a specific customer's cart\n",
    "cart_response = requests.get('http://localhost:3001/api/customers/cust01/cart')\n",
    "print(\"\\nCustomer cart:\")\n",
    "print(json.dumps(cart_response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897654e6",
   "metadata": {},
   "source": [
    "## 3. Fetching and Processing All Cart Data\n",
    "\n",
    "Now that we have confirmed our server is working, let's fetch all the customer data and transform it into DataFrames for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all customer data\n",
    "all_customers = requests.get('http://localhost:3001/api/customers').json()\n",
    "\n",
    "# Create a DataFrame for customer information\n",
    "customers_df = pd.DataFrame([\n",
    "    {\n",
    "        'customer_id': customer['id'],\n",
    "        'customer_name': customer['name'],\n",
    "        'cart_items': len(customer['cart']),\n",
    "        'total_quantity': sum(item['quantity'] for item in customer['cart']),\n",
    "        'cart_value': sum(item['price'] * item['quantity'] for item in customer['cart'])\n",
    "    }\n",
    "    for customer in all_customers\n",
    "])\n",
    "\n",
    "# Create a DataFrame for all cart items\n",
    "cart_items = []\n",
    "for customer in all_customers:\n",
    "    for item in customer['cart']:\n",
    "        cart_items.append({\n",
    "            'customer_id': customer['id'],\n",
    "            'customer_name': customer['name'],\n",
    "            'product_id': item['id'],\n",
    "            'product_name': item['name'],\n",
    "            'price': item['price'],\n",
    "            'quantity': item['quantity'],\n",
    "            'category': item['category'],\n",
    "            'subtotal': item['price'] * item['quantity']\n",
    "        })\n",
    "\n",
    "cart_items_df = pd.DataFrame(cart_items)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Customer Summary:\")\n",
    "display(customers_df.head())\n",
    "\n",
    "print(\"\\nCart Items:\")\n",
    "display(cart_items_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63271800",
   "metadata": {},
   "source": [
    "## 4. Basic Cart Statistics\n",
    "\n",
    "Let's calculate some basic statistics about our customer carts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4652bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics\n",
    "total_revenue = customers_df['cart_value'].sum()\n",
    "average_cart_value = customers_df['cart_value'].mean()\n",
    "median_cart_value = customers_df['cart_value'].median()\n",
    "max_cart_value = customers_df['cart_value'].max()\n",
    "min_cart_value = customers_df['cart_value'].min()\n",
    "total_items_sold = cart_items_df['quantity'].sum()\n",
    "average_items_per_cart = customers_df['total_quantity'].mean()\n",
    "unique_categories = cart_items_df['category'].nunique()\n",
    "unique_products = cart_items_df['product_id'].nunique()\n",
    "\n",
    "# Display statistics\n",
    "stats = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Revenue', \n",
    "        'Average Cart Value', \n",
    "        'Median Cart Value',\n",
    "        'Maximum Cart Value',\n",
    "        'Minimum Cart Value',\n",
    "        'Total Items Sold',\n",
    "        'Average Items per Cart',\n",
    "        'Unique Categories',\n",
    "        'Unique Products'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"${total_revenue:.2f}\",\n",
    "        f\"${average_cart_value:.2f}\",\n",
    "        f\"${median_cart_value:.2f}\",\n",
    "        f\"${max_cart_value:.2f}\",\n",
    "        f\"${min_cart_value:.2f}\",\n",
    "        total_items_sold,\n",
    "        f\"{average_items_per_cart:.1f}\",\n",
    "        unique_categories,\n",
    "        unique_products\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(stats)\n",
    "\n",
    "# Create a histogram of cart values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(customers_df['cart_value'], bins=10, kde=True)\n",
    "plt.title('Distribution of Cart Values')\n",
    "plt.xlabel('Cart Value ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot of items vs cart value\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=customers_df, x='total_quantity', y='cart_value', s=100, alpha=0.7)\n",
    "plt.title('Relationship Between Number of Items and Cart Value')\n",
    "plt.xlabel('Total Quantity of Items')\n",
    "plt.ylabel('Cart Value ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a04e8",
   "metadata": {},
   "source": [
    "## 5. Category Analysis\n",
    "\n",
    "Now let's analyze the product categories to see which ones are most popular and generate the most revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02049902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categories\n",
    "category_stats = cart_items_df.groupby('category').agg({\n",
    "    'product_id': 'count',\n",
    "    'quantity': 'sum',\n",
    "    'subtotal': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "category_stats.columns = ['Category', 'Product Count', 'Quantity Sold', 'Revenue']\n",
    "category_stats['Average Price'] = category_stats['Revenue'] / category_stats['Quantity Sold']\n",
    "category_stats = category_stats.sort_values('Revenue', ascending=False)\n",
    "\n",
    "# Display category statistics\n",
    "display(category_stats)\n",
    "\n",
    "# Create a bar chart of revenue by category\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=category_stats, x='Category', y='Revenue', palette='viridis')\n",
    "plt.title('Revenue by Product Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a pie chart of revenue distribution\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(\n",
    "    category_stats['Revenue'],\n",
    "    labels=category_stats['Category'],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    shadow=True,\n",
    "    explode=[0.05] * len(category_stats),\n",
    "    colors=sns.color_palette('viridis', len(category_stats))\n",
    ")\n",
    "plt.title('Revenue Distribution by Category')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Create a grouped bar chart for product count and quantity sold\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(category_stats))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, category_stats['Product Count'], width, label='Product Count')\n",
    "ax1.set_ylabel('Product Count')\n",
    "ax1.set_title('Product Count vs Quantity Sold by Category')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(category_stats['Category'], rotation=45)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.bar(x + width/2, category_stats['Quantity Sold'], width, color='orange', label='Quantity Sold')\n",
    "ax2.set_ylabel('Quantity Sold')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9d5b7",
   "metadata": {},
   "source": [
    "## 6. Price Range Analysis\n",
    "\n",
    "Let's analyze customer purchasing behavior across different price ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2145c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define price ranges\n",
    "def assign_price_range(price):\n",
    "    if price < 20:\n",
    "        return 'Low (< $20)'\n",
    "    elif price < 50:\n",
    "        return 'Medium ($20-$49)'\n",
    "    elif price < 100:\n",
    "        return 'High ($50-$99)'\n",
    "    else:\n",
    "        return 'Premium ($100+)'\n",
    "\n",
    "# Add price range column\n",
    "cart_items_df['price_range'] = cart_items_df['price'].apply(assign_price_range)\n",
    "\n",
    "# Analyze products by price range\n",
    "price_range_stats = cart_items_df.groupby('price_range').agg({\n",
    "    'product_id': 'count',\n",
    "    'quantity': 'sum',\n",
    "    'subtotal': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "price_range_stats.columns = ['Price Range', 'Product Count', 'Quantity Sold', 'Revenue']\n",
    "price_range_stats['Average Quantity per Product'] = price_range_stats['Quantity Sold'] / price_range_stats['Product Count']\n",
    "\n",
    "# Define correct sorting order\n",
    "price_range_order = ['Low (< $20)', 'Medium ($20-$49)', 'High ($50-$99)', 'Premium ($100+)']\n",
    "price_range_stats['Price Range'] = pd.Categorical(\n",
    "    price_range_stats['Price Range'],\n",
    "    categories=price_range_order,\n",
    "    ordered=True\n",
    ")\n",
    "price_range_stats = price_range_stats.sort_values('Price Range')\n",
    "\n",
    "# Display price range statistics\n",
    "display(price_range_stats)\n",
    "\n",
    "# Create a bar chart of revenue by price range\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=price_range_stats, x='Price Range', y='Revenue', palette='rocket')\n",
    "plt.title('Revenue by Price Range')\n",
    "plt.xlabel('Price Range')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a bar chart of quantity sold by price range\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=price_range_stats, x='Price Range', y='Quantity Sold', palette='rocket')\n",
    "plt.title('Quantity Sold by Price Range')\n",
    "plt.xlabel('Price Range')\n",
    "plt.ylabel('Quantity Sold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a more detailed analysis with categories and price ranges\n",
    "category_price_stats = cart_items_df.groupby(['category', 'price_range']).agg({\n",
    "    'product_id': 'count',\n",
    "    'quantity': 'sum',\n",
    "    'subtotal': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "category_price_stats.columns = ['Category', 'Price Range', 'Product Count', 'Quantity Sold', 'Revenue']\n",
    "category_price_stats['Price Range'] = pd.Categorical(\n",
    "    category_price_stats['Price Range'],\n",
    "    categories=price_range_order,\n",
    "    ordered=True\n",
    ")\n",
    "category_price_stats = category_price_stats.sort_values(['Category', 'Price Range'])\n",
    "\n",
    "# Display category and price range statistics\n",
    "display(category_price_stats.head(10))\n",
    "\n",
    "# Create a heatmap of revenue by category and price range\n",
    "pivot_data = category_price_stats.pivot_table(\n",
    "    values='Revenue',\n",
    "    index='Category',\n",
    "    columns='Price Range',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='YlGnBu', linewidths=.5)\n",
    "plt.title('Revenue by Category and Price Range')\n",
    "plt.ylabel('Category')\n",
    "plt.xlabel('Price Range')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50e25d",
   "metadata": {},
   "source": [
    "## 11. Advanced Visualization and Cross-Analysis\n",
    "\n",
    "Let's create more advanced visualizations to show relationships between different factors in our cart data, such as correlations between product categories, price ranges, and customer demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10488b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a customer demographics dataframe with additional information\n",
    "customer_demographics = customer_spending.copy()\n",
    "\n",
    "# Simulate customer ages and genders for demonstration purposes\n",
    "np.random.seed(42)  # For reproducibility\n",
    "customer_demographics['age'] = np.random.randint(18, 75, size=len(customer_demographics))\n",
    "customer_demographics['gender'] = np.random.choice(['Male', 'Female', 'Other'], size=len(customer_demographics), p=[0.48, 0.48, 0.04])\n",
    "\n",
    "# Create age groups\n",
    "bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "labels = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "customer_demographics['age_group'] = pd.cut(customer_demographics['age'], bins=bins, labels=labels)\n",
    "\n",
    "# Merge with category preferences\n",
    "category_preferences = []\n",
    "\n",
    "for customer_id in customer_demographics['id']:\n",
    "    # Get customer's products\n",
    "    products = all_products_df[all_products_df['customer_id'] == customer_id]\n",
    "    \n",
    "    if len(products) > 0:\n",
    "        # Get most purchased category\n",
    "        category_counts = products.groupby('category').size()\n",
    "        if not category_counts.empty:\n",
    "            favorite_category = category_counts.idxmax()\n",
    "        else:\n",
    "            favorite_category = 'none'\n",
    "    else:\n",
    "        favorite_category = 'none'\n",
    "    \n",
    "    category_preferences.append(favorite_category)\n",
    "\n",
    "customer_demographics['favorite_category'] = category_preferences\n",
    "\n",
    "# Display demographics summary\n",
    "print(\"Customer Demographics Summary:\")\n",
    "print(f\"Total Customers: {len(customer_demographics)}\")\n",
    "print(f\"Gender Distribution: {customer_demographics['gender'].value_counts().to_dict()}\")\n",
    "print(f\"Age Group Distribution: {customer_demographics['age_group'].value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Favorite Category Distribution: {customer_demographics['favorite_category'].value_counts().to_dict()}\")\n",
    "\n",
    "# Create visualizations for demographics analysis\n",
    "\n",
    "# Plot age distribution\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Age group spending\n",
    "plt.subplot(2, 2, 1)\n",
    "age_spending = customer_demographics.groupby('age_group')['total_spending'].mean().sort_index()\n",
    "sns.barplot(x=age_spending.index, y=age_spending.values, palette='viridis')\n",
    "plt.title('Average Spending by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Average Spending ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Gender spending\n",
    "plt.subplot(2, 2, 2)\n",
    "gender_spending = customer_demographics.groupby('gender')['total_spending'].mean()\n",
    "sns.barplot(x=gender_spending.index, y=gender_spending.values, palette='magma')\n",
    "plt.title('Average Spending by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Average Spending ($)')\n",
    "\n",
    "# Category preferences by age group\n",
    "plt.subplot(2, 2, 3)\n",
    "cat_age = pd.crosstab(customer_demographics['age_group'], customer_demographics['favorite_category'])\n",
    "cat_age_pct = cat_age.div(cat_age.sum(axis=1), axis=0) * 100\n",
    "cat_age_pct.plot(kind='bar', stacked=True, colormap='tab10', figsize=(10, 6))\n",
    "plt.title('Category Preferences by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Category preferences by gender\n",
    "plt.subplot(2, 2, 4)\n",
    "cat_gender = pd.crosstab(customer_demographics['gender'], customer_demographics['favorite_category'])\n",
    "cat_gender_pct = cat_gender.div(cat_gender.sum(axis=1), axis=0) * 100\n",
    "cat_gender_pct.plot(kind='bar', stacked=True, colormap='tab10')\n",
    "plt.title('Category Preferences by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create correlation heatmap between age, spending and quantity\n",
    "correlation_data = pd.DataFrame({\n",
    "    'age': customer_demographics['age'],\n",
    "    'total_spending': customer_demographics['total_spending'],\n",
    "    'segment_value': customer_demographics['segment'].map({'Low': 1, 'Medium': 2, 'High': 3, 'VIP': 4})\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = correlation_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Between Age, Spending, and Customer Segment')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot with age vs spending, colored by segment\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=customer_demographics,\n",
    "    x='age',\n",
    "    y='total_spending',\n",
    "    hue='segment',\n",
    "    palette='viridis',\n",
    "    size='total_spending',\n",
    "    sizes=(20, 200),\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('Customer Age vs. Spending by Segment')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Total Spending ($)')\n",
    "plt.legend(title='Customer Segment')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Display summary of findings\n",
    "print(\"\\nKey Insights from Demographics Analysis:\")\n",
    "print(\"1. Age Correlation with Spending:\", round(correlation_matrix.loc['age', 'total_spending'], 2))\n",
    "print(\"2. Most Popular Category Overall:\", customer_demographics['favorite_category'].value_counts().idxmax())\n",
    "print(\"3. Age Group with Highest Average Spending:\", age_spending.idxmax(), f\"(${round(age_spending.max(), 2)})\")\n",
    "print(\"4. Gender with Highest Average Spending:\", gender_spending.idxmax(), f\"(${round(gender_spending.max(), 2)})\")\n",
    "\n",
    "# Create a final recommendation summary based on demographics\n",
    "print(\"\\nRecommendations Based on Demographics Analysis:\")\n",
    "high_spending_age = age_spending.idxmax()\n",
    "high_spending_gender = gender_spending.idxmax()\n",
    "popular_category = customer_demographics['favorite_category'].value_counts().idxmax()\n",
    "\n",
    "print(f\"1. Target marketing campaigns toward {high_spending_age} age group as they spend the most on average.\")\n",
    "print(f\"2. Consider special promotions for {high_spending_gender} shoppers to leverage their higher spending patterns.\")\n",
    "print(f\"3. Expand {popular_category} product offerings as it's the most popular category across demographics.\")\n",
    "print(\"4. Use age and gender preferences to create personalized product recommendations.\")\n",
    "print(\"5. Develop loyalty programs for VIP segment customers to maintain their high spending levels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05649345",
   "metadata": {},
   "source": [
    "## 12. Time Series Analysis of Cart Data\n",
    "\n",
    "Let's analyze how cart data changes over time to identify trends, seasonal patterns, and potential growth opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2853c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate historical cart data for time series analysis\n",
    "# Using a simulated dataset since our original data doesn't have timestamps\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate dates for the past 12 months\n",
    "end_date = pd.Timestamp.now()\n",
    "start_date = end_date - pd.DateOffset(months=12)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Create a time series dataframe\n",
    "ts_data = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'orders': np.random.randint(10, 50, size=len(date_range)),  # Random number of orders per day\n",
    "})\n",
    "\n",
    "# Add some seasonality and trend\n",
    "ts_data['month'] = ts_data['date'].dt.month\n",
    "ts_data['day_of_week'] = ts_data['date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "ts_data['is_weekend'] = ts_data['day_of_week'] >= 5  # Weekend indicator\n",
    "\n",
    "# Add seasonal effects (higher in certain months like November-December for holidays)\n",
    "month_effects = {\n",
    "    1: -5,    # January (post-holiday dip)\n",
    "    2: -10,   # February (lowest)\n",
    "    3: 0,     # March\n",
    "    4: 5,     # April\n",
    "    5: 10,    # May\n",
    "    6: 5,     # June\n",
    "    7: 0,     # July\n",
    "    8: 15,    # August (back to school)\n",
    "    9: 5,     # September\n",
    "    10: 10,   # October\n",
    "    11: 30,   # November (early holiday shopping)\n",
    "    12: 50,   # December (holiday shopping peak)\n",
    "}\n",
    "\n",
    "# Add day-of-week effects (weekends higher than weekdays)\n",
    "dow_effects = {\n",
    "    0: 0,     # Monday\n",
    "    1: 5,     # Tuesday\n",
    "    2: 10,    # Wednesday\n",
    "    3: 15,    # Thursday\n",
    "    4: 25,    # Friday\n",
    "    5: 40,    # Saturday\n",
    "    6: 30,    # Sunday\n",
    "}\n",
    "\n",
    "# Apply seasonal effects\n",
    "for month, effect in month_effects.items():\n",
    "    ts_data.loc[ts_data['month'] == month, 'orders'] += effect\n",
    "\n",
    "for dow, effect in dow_effects.items():\n",
    "    ts_data.loc[ts_data['day_of_week'] == dow, 'orders'] += effect\n",
    "\n",
    "# Add a general upward trend (business growth)\n",
    "days = (ts_data['date'] - ts_data['date'].min()).dt.days\n",
    "ts_data['trend'] = days * 0.1  # Slight upward trend\n",
    "ts_data['orders'] = ts_data['orders'] + ts_data['trend']\n",
    "\n",
    "# Add some random special event spikes\n",
    "special_events = pd.DataFrame({\n",
    "    'date': [\n",
    "        pd.Timestamp(year=end_date.year-1, month=11, day=25),  # Black Friday\n",
    "        pd.Timestamp(year=end_date.year-1, month=12, day=15),  # Holiday shopping peak\n",
    "        pd.Timestamp(year=end_date.year, month=1, day=1),      # New Year\n",
    "        pd.Timestamp(year=end_date.year, month=2, day=14),     # Valentine's Day\n",
    "        pd.Timestamp(year=end_date.year, month=5, day=15),     # Spring sale\n",
    "        pd.Timestamp(year=end_date.year, month=7, day=4),      # Independence Day\n",
    "    ],\n",
    "    'effect': [100, 80, 30, 50, 40, 60]\n",
    "})\n",
    "\n",
    "# Apply special event effects\n",
    "for _, event in special_events.iterrows():\n",
    "    event_date = event['date'].strftime('%Y-%m-%d')\n",
    "    if event_date in ts_data['date'].dt.strftime('%Y-%m-%d').values:\n",
    "        ts_data.loc[ts_data['date'].dt.strftime('%Y-%m-%d') == event_date, 'orders'] += event['effect']\n",
    "\n",
    "# Ensure we have realistic values (no negative values)\n",
    "ts_data['orders'] = ts_data['orders'].clip(lower=5).astype(int)\n",
    "\n",
    "# Calculate revenue assuming average order value varies by month\n",
    "average_order_values = {\n",
    "    1: 45,    # January\n",
    "    2: 40,    # February\n",
    "    3: 50,    # March\n",
    "    4: 55,    # April\n",
    "    5: 60,    # May\n",
    "    6: 65,    # June\n",
    "    7: 70,    # July\n",
    "    8: 80,    # August (back to school)\n",
    "    9: 65,    # September\n",
    "    10: 70,   # October\n",
    "    11: 85,   # November (early holiday shopping)\n",
    "    12: 95,   # December (holiday shopping peak)\n",
    "}\n",
    "\n",
    "# Apply average order values\n",
    "ts_data['avg_order_value'] = ts_data['month'].map(average_order_values)\n",
    "ts_data['revenue'] = ts_data['orders'] * ts_data['avg_order_value']\n",
    "\n",
    "# Also generate category mix over time\n",
    "categories = ['electronics', 'clothing', 'home', 'beauty', 'books', 'food']\n",
    "for cat in categories:\n",
    "    # Create a base percentage for each category\n",
    "    base_pct = np.random.uniform(0.05, 0.3)\n",
    "    \n",
    "    # Add some monthly variation\n",
    "    month_variation = np.random.normal(0, 0.05, 12)\n",
    "    \n",
    "    # Create monthly percentages\n",
    "    month_pcts = {m: max(0.01, base_pct + month_variation[m-1]) for m in range(1, 13)}\n",
    "    \n",
    "    # Apply to dataframe\n",
    "    ts_data[f'{cat}_pct'] = ts_data['month'].map(month_pcts)\n",
    "\n",
    "# Normalize percentages so they sum to 1 for each day\n",
    "pct_columns = [f'{cat}_pct' for cat in categories]\n",
    "row_sums = ts_data[pct_columns].sum(axis=1)\n",
    "for col in pct_columns:\n",
    "    ts_data[col] = ts_data[col] / row_sums\n",
    "\n",
    "# Calculate category revenue\n",
    "for cat in categories:\n",
    "    ts_data[f'{cat}_revenue'] = ts_data['revenue'] * ts_data[f'{cat}_pct']\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_data = ts_data.groupby(ts_data['date'].dt.strftime('%Y-%m')).agg({\n",
    "    'orders': 'sum',\n",
    "    'revenue': 'sum',\n",
    "    **{f'{cat}_revenue': 'sum' for cat in categories}\n",
    "}).reset_index()\n",
    "monthly_data['date'] = pd.to_datetime(monthly_data['date'] + '-01')\n",
    "monthly_data = monthly_data.sort_values('date')\n",
    "\n",
    "# Weekly aggregation\n",
    "weekly_data = ts_data.groupby(pd.Grouper(key='date', freq='W-MON')).agg({\n",
    "    'orders': 'sum',\n",
    "    'revenue': 'sum',\n",
    "    'avg_order_value': 'mean',\n",
    "    **{f'{cat}_revenue': 'sum' for cat in categories}\n",
    "}).reset_index()\n",
    "weekly_data = weekly_data.sort_values('date')\n",
    "\n",
    "# Display overview of the time series data\n",
    "print(\"Time Series Data Overview:\")\n",
    "print(f\"Date Range: {ts_data['date'].min().strftime('%Y-%m-%d')} to {ts_data['date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Total Days: {len(ts_data)}\")\n",
    "print(f\"Total Orders: {ts_data['orders'].sum():,}\")\n",
    "print(f\"Total Revenue: ${ts_data['revenue'].sum():,.2f}\")\n",
    "print(\"\\nTop 5 Highest Revenue Days:\")\n",
    "display(ts_data.sort_values('revenue', ascending=False).head(5)[['date', 'orders', 'revenue', 'avg_order_value']])\n",
    "\n",
    "# Time series visualizations\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Daily orders with 7-day moving average\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(ts_data['date'], ts_data['orders'], color='skyblue', alpha=0.5, label='Daily Orders')\n",
    "plt.plot(ts_data['date'], ts_data['orders'].rolling(7).mean(), color='blue', linewidth=2, label='7-Day Moving Avg')\n",
    "plt.title('Daily Orders with 7-Day Moving Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly revenue\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.bar(monthly_data['date'], monthly_data['revenue'], color='green', alpha=0.7)\n",
    "plt.title('Monthly Revenue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Revenue by category over time (stacked area chart)\n",
    "plt.subplot(3, 1, 3)\n",
    "category_columns = [f'{cat}_revenue' for cat in categories]\n",
    "monthly_data_stacked = monthly_data.copy()\n",
    "plt.stackplot(monthly_data_stacked['date'], \n",
    "              [monthly_data_stacked[col] for col in category_columns],\n",
    "              labels=categories, alpha=0.7)\n",
    "plt.title('Monthly Revenue by Category')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Day of week analysis\n",
    "dow_analysis = ts_data.groupby('day_of_week').agg({\n",
    "    'orders': 'mean',\n",
    "    'revenue': 'mean',\n",
    "    'avg_order_value': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "dow_analysis['day_name'] = dow_analysis['day_of_week'].map({\n",
    "    0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', \n",
    "    4: 'Friday', 5: 'Saturday', 6: 'Sunday'\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='day_name', y='orders', data=dow_analysis, palette='viridis')\n",
    "plt.title('Average Daily Orders by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Orders')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='day_name', y='revenue', data=dow_analysis, palette='viridis')\n",
    "plt.title('Average Daily Revenue by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Revenue ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Monthly category analysis\n",
    "plt.figure(figsize=(14, 8))\n",
    "for i, cat in enumerate(categories):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(monthly_data['date'], monthly_data[f'{cat}_revenue'], marker='o')\n",
    "    plt.title(f'{cat.capitalize()} Revenue Trend')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Revenue ($)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display insights\n",
    "print(\"\\nKey Time Series Insights:\")\n",
    "print(f\"1. Highest Revenue Month: {monthly_data.loc[monthly_data['revenue'].idxmax(), 'date'].strftime('%B %Y')}\")\n",
    "print(f\"2. Highest Revenue Day of Week: {dow_analysis.loc[dow_analysis['revenue'].idxmax(), 'day_name']}\")\n",
    "print(f\"3. Most Consistent Category: {min([(cat, monthly_data[f'{cat}_revenue'].std() / monthly_data[f'{cat}_revenue'].mean()) for cat in categories], key=lambda x: x[1])[0].capitalize()}\")\n",
    "print(f\"4. Fastest Growing Category: {max([(cat, monthly_data[f'{cat}_revenue'].iloc[-1] / monthly_data[f'{cat}_revenue'].iloc[0] - 1) for cat in categories], key=lambda x: x[1])[0].capitalize()}\")\n",
    "\n",
    "# Generate forecasts (simple moving average)\n",
    "forecast_window = 3  # months\n",
    "forecasted_months = []\n",
    "forecasted_revenue = []\n",
    "\n",
    "last_date = monthly_data['date'].iloc[-1]\n",
    "for i in range(1, forecast_window + 1):\n",
    "    next_month = last_date + pd.DateOffset(months=i)\n",
    "    forecasted_months.append(next_month)\n",
    "    \n",
    "    # Simple moving average of last 3 months\n",
    "    last_3_months_avg = monthly_data['revenue'].iloc[-3:].mean()\n",
    "    forecasted_revenue.append(last_3_months_avg)\n",
    "\n",
    "forecast_df = pd.DataFrame({\n",
    "    'date': forecasted_months,\n",
    "    'forecasted_revenue': forecasted_revenue\n",
    "})\n",
    "\n",
    "# Plot actual vs forecasted revenue\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_data['date'], monthly_data['revenue'], marker='o', color='blue', label='Actual Revenue')\n",
    "plt.plot(forecast_df['date'], forecast_df['forecasted_revenue'], marker='o', color='red', linestyle='--', label='Forecasted Revenue')\n",
    "plt.title('Revenue Forecast for Next 3 Months')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRevenue Forecast for Next 3 Months:\")\n",
    "for i, row in forecast_df.iterrows():\n",
    "    print(f\"{row['date'].strftime('%B %Y')}: ${row['forecasted_revenue']:,.2f}\")\n",
    "\n",
    "# Time series recommendations\n",
    "print(\"\\nRecommendations Based on Time Series Analysis:\")\n",
    "best_day = dow_analysis.loc[dow_analysis['revenue'].idxmax(), 'day_name']\n",
    "print(f\"1. Focus marketing campaigns on {best_day}s as they generate the highest average revenue.\")\n",
    "print(f\"2. Prepare inventory for increased demand in {monthly_data.loc[monthly_data['revenue'].idxmax(), 'date'].strftime('%B')}.\")\n",
    "print(\"3. Develop targeted promotions for lower-revenue months to smooth out seasonal variations.\")\n",
    "print(\"4. Analyze special event spikes to identify successful promotion strategies.\")\n",
    "print(\"5. Adjust staffing levels based on day-of-week order patterns to ensure optimal customer service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532de0e1",
   "metadata": {},
   "source": [
    "## 13. Predictive Analytics and AI Recommendations\n",
    "\n",
    "In this section, we'll use machine learning to create a simple recommendation system and predictive model based on our cart data. This demonstrates how the MCP Cart Analysis tool could use AI to generate personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for machine learning\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "print(\"Building AI recommendation and prediction models...\")\n",
    "\n",
    "# Create a more detailed customer purchase dataset\n",
    "# This will simulate purchase history for customers\n",
    "\n",
    "# First, get all unique products from the cart data\n",
    "all_products = pd.DataFrame()\n",
    "for customer_id, customer_data in customers_df.iterrows():\n",
    "    if 'cart' in customer_data and isinstance(customer_data['cart'], list):\n",
    "        for item in customer_data['cart']:\n",
    "            all_products = pd.concat([all_products, pd.DataFrame([{\n",
    "                'customer_id': customer_data['id'],\n",
    "                'product_id': item.get('id', ''),\n",
    "                'product_name': item.get('name', ''),\n",
    "                'category': item.get('category', 'uncategorized'),\n",
    "                'price': item.get('price', 0),\n",
    "                'quantity': item.get('quantity', 1)\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "# Merge with customer demographics\n",
    "customer_purchase_data = all_products.merge(\n",
    "    customer_demographics[['id', 'age', 'gender', 'age_group', 'total_spending']],\n",
    "    left_on='customer_id',\n",
    "    right_on='id'\n",
    ")\n",
    "\n",
    "# Create a product purchase matrix (customer-product matrix)\n",
    "purchase_matrix = customer_purchase_data.pivot_table(\n",
    "    index='customer_id',\n",
    "    columns='category',\n",
    "    values='quantity',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Ensure all categories are represented\n",
    "for category in ['electronics', 'clothing', 'home', 'food', 'beauty', 'books']:\n",
    "    if category not in purchase_matrix.columns:\n",
    "        purchase_matrix[category] = 0\n",
    "\n",
    "# Generate additional features for our predictive model\n",
    "customer_features = customer_demographics.copy()\n",
    "# Add purchase frequency per category\n",
    "for category in purchase_matrix.columns:\n",
    "    customer_features = customer_features.merge(\n",
    "        purchase_matrix[category].reset_index().rename(columns={category: f'{category}_quantity'}),\n",
    "        left_on='id',\n",
    "        right_on='customer_id',\n",
    "        how='left'\n",
    "    )\n",
    "    customer_features[f'{category}_quantity'] = customer_features[f'{category}_quantity'].fillna(0)\n",
    "\n",
    "# Feature: total number of categories purchased\n",
    "customer_features['category_diversity'] = customer_features[[f'{cat}_quantity' for cat in purchase_matrix.columns]].gt(0).sum(axis=1)\n",
    "\n",
    "# Add average price point preference (weighted by quantity)\n",
    "customer_avg_price = customer_purchase_data.groupby('customer_id').apply(\n",
    "    lambda x: (x['price'] * x['quantity']).sum() / x['quantity'].sum() if x['quantity'].sum() > 0 else 0\n",
    ").reset_index().rename(columns={0: 'avg_price_preference'})\n",
    "\n",
    "customer_features = customer_features.merge(\n",
    "    customer_avg_price,\n",
    "    left_on='id',\n",
    "    right_on='customer_id',\n",
    "    how='left'\n",
    ")\n",
    "customer_features['avg_price_preference'] = customer_features['avg_price_preference'].fillna(0)\n",
    "\n",
    "# Display feature set\n",
    "print(\"\\nCustomer Features for Predictive Models:\")\n",
    "display(customer_features.head())\n",
    "\n",
    "# 1. Customer Segmentation using K-means\n",
    "# Prepare data for clustering\n",
    "cluster_features = customer_features[[\n",
    "    'total_spending', 'avg_price_preference', 'category_diversity',\n",
    "    'age'\n",
    "]].copy()\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "cluster_data_scaled = scaler.fit_transform(cluster_features)\n",
    "\n",
    "# Determine optimal number of clusters using elbow method\n",
    "inertias = []\n",
    "k_range = range(2, 8)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(cluster_data_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'o-', color='blue')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Apply K-means with chosen number of clusters\n",
    "k = 4  # Based on elbow method\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "customer_features['cluster'] = kmeans.fit_predict(cluster_data_scaled)\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_analysis = customer_features.groupby('cluster').agg({\n",
    "    'total_spending': 'mean',\n",
    "    'avg_price_preference': 'mean',\n",
    "    'category_diversity': 'mean',\n",
    "    'age': 'mean',\n",
    "    **{f'{cat}_quantity': 'mean' for cat in purchase_matrix.columns}\n",
    "}).reset_index()\n",
    "\n",
    "# Display cluster profiles\n",
    "print(\"\\nCustomer Segment Profiles:\")\n",
    "display(cluster_analysis)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, feature_pair in enumerate([\n",
    "    ('total_spending', 'avg_price_preference'),\n",
    "    ('category_diversity', 'age')\n",
    "]):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    scatter = plt.scatter(\n",
    "        customer_features[feature_pair[0]], \n",
    "        customer_features[feature_pair[1]], \n",
    "        c=customer_features['cluster'], \n",
    "        cmap='viridis',\n",
    "        s=50,\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.xlabel(feature_pair[0])\n",
    "    plt.ylabel(feature_pair[1])\n",
    "    plt.title(f'Clusters by {feature_pair[0]} and {feature_pair[1]}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Assign descriptive labels to clusters\n",
    "cluster_labels = {\n",
    "    0: \"Budget Shoppers\",      # Low spending, low price point\n",
    "    1: \"Selective Shoppers\",   # Medium spending, medium diversity\n",
    "    2: \"Premium Shoppers\",     # High spending, high price point\n",
    "    3: \"Diverse Shoppers\"      # Medium spending, high diversity\n",
    "}\n",
    "\n",
    "# Map cluster numbers to labels\n",
    "customer_features['segment_label'] = customer_features['cluster'].map(cluster_labels)\n",
    "\n",
    "# Print cluster distribution\n",
    "print(\"\\nCustomer Segment Distribution:\")\n",
    "segment_dist = customer_features['segment_label'].value_counts()\n",
    "for segment, count in segment_dist.items():\n",
    "    print(f\"  {segment}: {count} customers ({count/len(customer_features)*100:.1f}%)\")\n",
    "\n",
    "# 2. Product Recommendation Model\n",
    "# Create a simple collaborative filtering system\n",
    "\n",
    "# Function to find similar customers\n",
    "def find_similar_customers(customer_id, purchase_matrix, n=3):\n",
    "    \"\"\"Find the most similar customers based on purchase patterns\"\"\"\n",
    "    if customer_id not in purchase_matrix.index:\n",
    "        return []\n",
    "    \n",
    "    # Get the target customer's purchase pattern\n",
    "    target_pattern = purchase_matrix.loc[customer_id].values\n",
    "    \n",
    "    # Calculate similarity with all other customers\n",
    "    similarities = {}\n",
    "    for cust_id in purchase_matrix.index:\n",
    "        if cust_id == customer_id:\n",
    "            continue\n",
    "        \n",
    "        other_pattern = purchase_matrix.loc[cust_id].values\n",
    "        \n",
    "        # Use cosine similarity\n",
    "        dot_product = np.dot(target_pattern, other_pattern)\n",
    "        norm_target = np.linalg.norm(target_pattern)\n",
    "        norm_other = np.linalg.norm(other_pattern)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if norm_target == 0 or norm_other == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            similarity = dot_product / (norm_target * norm_other)\n",
    "        \n",
    "        similarities[cust_id] = similarity\n",
    "    \n",
    "    # Sort by similarity and return top n\n",
    "    similar_customers = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    return similar_customers\n",
    "\n",
    "# Function to recommend products\n",
    "def recommend_products(customer_id, purchase_matrix, all_products, n=3):\n",
    "    \"\"\"Recommend products based on similar customers\"\"\"\n",
    "    similar_customers = find_similar_customers(customer_id, purchase_matrix)\n",
    "    \n",
    "    if not similar_customers:\n",
    "        return []\n",
    "    \n",
    "    # Get products purchased by the target customer\n",
    "    if customer_id in purchase_matrix.index:\n",
    "        target_purchases = set(all_products[all_products['customer_id'] == customer_id]['product_id'])\n",
    "    else:\n",
    "        target_purchases = set()\n",
    "    \n",
    "    # Collect products from similar customers\n",
    "    recommended_products = {}\n",
    "    \n",
    "    for similar_id, similarity in similar_customers:\n",
    "        # Get products this similar customer purchased\n",
    "        similar_purchases = all_products[all_products['customer_id'] == similar_id]\n",
    "        \n",
    "        # Add to recommendations if not already purchased by target\n",
    "        for _, product in similar_purchases.iterrows():\n",
    "            if product['product_id'] not in target_purchases:\n",
    "                if product['product_id'] not in recommended_products:\n",
    "                    recommended_products[product['product_id']] = {\n",
    "                        'product_id': product['product_id'],\n",
    "                        'product_name': product['product_name'],\n",
    "                        'category': product['category'],\n",
    "                        'price': product['price'],\n",
    "                        'score': similarity\n",
    "                    }\n",
    "                else:\n",
    "                    # If already recommended, increase the score\n",
    "                    recommended_products[product['product_id']]['score'] += similarity\n",
    "    \n",
    "    # Sort by score and return top n\n",
    "    sorted_recommendations = sorted(recommended_products.values(), key=lambda x: x['score'], reverse=True)[:n]\n",
    "    return sorted_recommendations\n",
    "\n",
    "# Test recommendations for a sample customer\n",
    "sample_customer_id = customer_features['id'].iloc[2]  # Arbitrary customer\n",
    "print(f\"\\nProduct Recommendations for Customer {sample_customer_id}:\")\n",
    "\n",
    "recommendations = recommend_products(sample_customer_id, purchase_matrix, all_products)\n",
    "if recommendations:\n",
    "    customer_name = customer_demographics[customer_demographics['id'] == sample_customer_id]['name'].iloc[0]\n",
    "    print(f\"Recommendations for {customer_name}:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec['product_name']} (${rec['price']:.2f}) - Category: {rec['category']}\")\n",
    "else:\n",
    "    print(\"No recommendations available for this customer.\")\n",
    "\n",
    "# 3. Predict Customer Spending\n",
    "# Build a regression model to predict total spending\n",
    "\n",
    "# Prepare features and target\n",
    "X = customer_features.drop(['id', 'name', 'customer_id', 'favorite_category', 'segment', 'cluster', 'segment_label', 'total_spending'], axis=1)\n",
    "y = customer_features['total_spending']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "categorical_features = ['gender', 'age_group']\n",
    "numerical_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Build and train model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\nSpending Prediction Model Performance:\")\n",
    "print(f\"  Root Mean Squared Error: ${rmse:.2f}\")\n",
    "print(f\"  Mean Absolute Error: ${np.mean(np.abs(y_test - y_pred)):.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "if hasattr(model['regressor'], 'feature_importances_'):\n",
    "    # Get feature names after preprocessing\n",
    "    preprocessed_features = []\n",
    "    for name, transformer, features in preprocessor.transformers_:\n",
    "        if name == 'num':\n",
    "            preprocessed_features.extend(features)\n",
    "        elif name == 'cat':\n",
    "            preprocessed_features.extend([f\"{feature}_{category}\" for feature in features \n",
    "                                        for category in transformer.categories_[preprocessor.transformers_[1][2].index(feature)]])\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = model['regressor'].feature_importances_\n",
    "    \n",
    "    # If the lengths match, we can create a proper mapping\n",
    "    if len(preprocessed_features) == len(importances):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': preprocessed_features,\n",
    "            'Importance': importances\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        # Plot top 10 features\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10))\n",
    "        plt.title('Top 10 Features for Predicting Customer Spending')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nTop 5 Factors Influencing Customer Spending:\")\n",
    "        for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "            print(f\"  {i}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "# 4. Combine everything for comprehensive customer insights\n",
    "print(\"\\nComprehensive Customer Insights Tool\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def analyze_customer(customer_id):\n",
    "    \"\"\"Provide comprehensive insights for a specific customer\"\"\"\n",
    "    # Get customer data\n",
    "    if customer_id not in customer_features['id'].values:\n",
    "        return \"Customer not found\"\n",
    "    \n",
    "    customer_data = customer_features[customer_features['id'] == customer_id].iloc[0]\n",
    "    \n",
    "    # Basic info\n",
    "    customer_name = customer_data['name']\n",
    "    cluster = customer_data['segment_label']\n",
    "    spending = customer_data['total_spending']\n",
    "    \n",
    "    # Get recommendations\n",
    "    product_recs = recommend_products(customer_id, purchase_matrix, all_products)\n",
    "    \n",
    "    # Generate insights\n",
    "    insights = {\n",
    "        \"customer_name\": customer_name,\n",
    "        \"segment\": cluster,\n",
    "        \"spending_level\": spending,\n",
    "        \"product_recommendations\": product_recs,\n",
    "        \"spending_percentile\": percentileofscore(customer_features['total_spending'], spending),\n",
    "        \"favorite_categories\": [col.replace('_quantity', '') for col in customer_features.columns if col.endswith('_quantity') \n",
    "                              and customer_data[col] > 0],\n",
    "        \"category_diversity_percentile\": percentileofscore(customer_features['category_diversity'], customer_data['category_diversity'])\n",
    "    }\n",
    "    \n",
    "    return insights\n",
    "\n",
    "# Test the analysis with a sample customer\n",
    "sample_customer = customer_features['id'].iloc[5]  # Different sample customer\n",
    "insights = analyze_customer(sample_customer)\n",
    "\n",
    "print(f\"Customer Analysis for: {insights['customer_name']}\")\n",
    "print(f\"Segment: {insights['segment']}\")\n",
    "print(f\"Spending: ${insights['spending_level']:.2f} (Higher than {insights['spending_percentile']:.1f}% of customers)\")\n",
    "print(f\"Category Diversity: Higher than {insights['category_diversity_percentile']:.1f}% of customers\")\n",
    "print(f\"Favorite Categories: {', '.join(insights['favorite_categories'])}\")\n",
    "\n",
    "print(\"\\nRecommended Products:\")\n",
    "for i, rec in enumerate(insights['product_recommendations'], 1):\n",
    "    print(f\"  {i}. {rec['product_name']} (${rec['price']:.2f}) - Category: {rec['category']}\")\n",
    "\n",
    "print(\"\\nMarketing Recommendations:\")\n",
    "if insights['segment'] == \"Budget Shoppers\":\n",
    "    print(\"  - Send discount coupons for everyday essentials\")\n",
    "    print(\"  - Highlight value-for-money promotions\")\n",
    "elif insights['segment'] == \"Premium Shoppers\":\n",
    "    print(\"  - Send exclusive offers for premium products\")\n",
    "    print(\"  - Highlight new arrivals and limited editions\")\n",
    "elif insights['segment'] == \"Diverse Shoppers\":\n",
    "    print(\"  - Send curated multi-category bundles\")\n",
    "    print(\"  - Highlight complementary products\")\n",
    "else:\n",
    "    print(\"  - Send personalized offers based on past category purchases\")\n",
    "    print(\"  - Highlight quality and uniqueness of products\")\n",
    "\n",
    "print(\"\\nThis is what the MCP Cart Analysis tool could provide when integrated with AI capabilities!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e631c83",
   "metadata": {},
   "source": [
    "## 14. Extended Conclusion\n",
    "\n",
    "In this comprehensive notebook, we have built a robust cart data analysis ecosystem that demonstrates how to:\n",
    "\n",
    "1. **Set up a dedicated cart data server** that provides structured access to shopping cart information\n",
    "2. **Integrate with an MCP server** for AI model access to rich cart data analysis\n",
    "3. **Perform diverse analytical approaches** from basic statistics to time series analysis\n",
    "4. **Build predictive models and recommendation systems** that can enhance the MCP tool capabilities\n",
    "\n",
    "This work illustrates how separating data provision (cart data server), analysis logic (MCP tools), and AI interaction (models) creates a powerful and flexible architecture. The MCP approach allows AI models to leverage specialized tools without needing to understand the underlying data structures or analysis algorithms.\n",
    "\n",
    "Future enhancements could include:\n",
    "- Real-time analytics capabilities\n",
    "- More sophisticated recommendation algorithms\n",
    "- Integration with actual e-commerce platforms\n",
    "- Enhanced visualization dashboards for business users\n",
    "- Natural language query capabilities for business analysts\n",
    "\n",
    "This notebook serves as both a demonstration of the integration architecture and a starting point for building production-ready cart analysis tools for AI systems."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
